<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Note</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="color-scheme" content="light dark">
    <link rel="canonical" href="https://nickrjx.github.io/32">
    <meta name="robots" content="index, follow">
  </head>
  <body style="max-width: 600px; font-family: monospace">
    &nbsp;<a href="/">Nick R.J. Blog</a>
    <br><br>
    <fieldset><legend><a href="32">Dec 9 2025</a> - <b>Note</b></legend><p>The Dwarkesh podcast with Ilya Sutskever was great. Well worth listening to.</p><p>A summary:</p><p>"here are the most important points from today's ilya sutskever podcast:</p><p>- superintelligence in 5-20 years<br> - current scaling will stall hard; we're back to real research<br> - superintelligence = super-fast continual learner, not finished oracle<br> - models generalize 100x worse than humans, the biggest AGI blocker<br> - need completely new ML paradigm (i have ideas, can't share rn)<br> - AI impact will hit hard, but only after economic diffusion<br> - breakthroughs historically needed almost no compute<br> - SSI has enough focused research compute to win<br> - current RL already eats more compute than pre-training"<br><a href="https://x.com/slow_developer/status/1993416904162328880">@slow_developer</a></p><p>"One point I made that didn’t come across:<br>- Scaling the current thing will keep leading to improvements.  In particular, it won’t stall.<br>- But something important will continue to be missing."<br><a href="https://x.com/ilyasut/status/1994424504370581726">@ilyasut</a></p><p><a href="https://www.youtube.com/watch?v=aR20FWCCjAs">https://www.youtube.com/watch?v=aR20FWCCjAs</a></p></fieldset>
    <br>
    &nbsp;<a href="/">More posts</a>
    <br><br><br>
  </body>
</html>
